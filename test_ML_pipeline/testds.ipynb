{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = ['n/a', 'na']\n",
    "df_train = pd.read_csv('titanic/train.csv', na_values = missing_values)\n",
    "df_test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = df_train.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiamos y procesamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_to_numerical(data_pd):\n",
    "    data_pd['Sex'] = data_pd['Sex'].map({'male':0, 'female':1})\n",
    "    data_pd['Embarked'] = data_pd['Embarked'].map({'C':0, 'Q':1, 'S':2})\n",
    "    \n",
    "    return data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.api.types as ptypes\n",
    "\n",
    "def test_categorical_to_numerical():\n",
    "    df = pd.DataFrame({\"PassengerId\": [1, 2, 3],\n",
    "                       \"Sex\": ['lala', 'male', 'female'],\n",
    "                       \"Embarked\": ['B', 'C', 'Q']}) #,\n",
    "                       # \"hola\": ['a', 'b', 'c']})\n",
    "    \n",
    "    df_cleaned = categorical_to_numerical(df)\n",
    "    \n",
    "    assert all(ptypes.is_numeric_dtype(df_cleaned[col]) for col in df_cleaned)\n",
    "    # True\n",
    "    # assert ptypes.is_string_dtype(df_cleaned['c'])\n",
    "    # True\n",
    "    # assert ptypes.is_datetime64_any_dtype(df_cleaned['d'])\n",
    "\n",
    "test_categorical_to_numerical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data_pd):\n",
    "    cleaned_data = data_pd.dropna(axis=0)\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clean_data():\n",
    "    df = pd.DataFrame({\"PassengerId\": [1, np.nan, 3],\n",
    "                       \"Sex\": [None, 'male', 'female'],\n",
    "                       \"Embarked\": ['B', 'C', 'Q'],\n",
    "                        \"hola\": ['null', 'b', 'c']})\n",
    "    \n",
    "    df_cleaned = clean_data(df)\n",
    "    assert df_cleaned.isna().any().any() == False\n",
    "\n",
    "test_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_values():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_remove_duplicate_values():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = categorical_to_numerical(df_train)\n",
    "df_test = categorical_to_numerical(df_test)\n",
    "\n",
    "df_train = clean_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "df_test = df_test.drop(columns=['Name', 'Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff451522f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(df_train.corr())\n",
    "tick_marks = [i for i in range(len(df_train.columns))]\n",
    "plt.xticks(tick_marks, df_train.columns, rotation='vertical')\n",
    "plt.yticks(tick_marks, df_train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "1             2         1       1    1  38.0      1      0  71.2833       0.0\n",
       "3             4         1       1    1  35.0      1      0  53.1000       2.0\n",
       "6             7         0       1    0  54.0      0      0  51.8625       2.0\n",
       "10           11         1       3    1   4.0      1      1  16.7000       2.0\n",
       "11           12         1       1    1  58.0      0      0  26.5500       2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['Survived']\n",
    "x_train = df_train.drop(columns=['Survived'])\n",
    "feature_vector_length = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_arquitecture():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=20, input_dim=feature_vector_length, activation='relu'))\n",
    "\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    # add dropout, default is none\n",
    "    model.add(Dropout(0.01))\n",
    "\n",
    "    # create output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # output layer\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobreentrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_arquitecture()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 3.7048 - acc: 0.3000\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6678 - acc: 0.7000\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6576 - acc: 0.8000\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.7113 - acc: 0.7000\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.5926 - acc: 0.8000\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.5871 - acc: 0.8000\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.5875 - acc: 0.8000\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.5699 - acc: 0.8000\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.5572 - acc: 0.8000\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.5867 - acc: 0.8000\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.5539 - acc: 0.8000\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.5548 - acc: 0.8000\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.5423 - acc: 0.8000\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.5455 - acc: 0.8000\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.5236 - acc: 0.8000\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4936 - acc: 0.8000\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.5708 - acc: 0.8000\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.5258 - acc: 0.8000\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4823 - acc: 0.8000\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.5330 - acc: 0.8000\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4853 - acc: 0.8000\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4991 - acc: 0.8000\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4650 - acc: 0.8000\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4237 - acc: 0.9000\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4485 - acc: 0.8000\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4628 - acc: 0.8000\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4848 - acc: 0.8000\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4142 - acc: 0.9000\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4501 - acc: 0.8000\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4641 - acc: 0.8000\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3793 - acc: 0.9000\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4288 - acc: 0.8000\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4687 - acc: 0.8000\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3953 - acc: 0.9000\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3811 - acc: 0.9000\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.3751 - acc: 0.9000\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4283 - acc: 0.8000\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4294 - acc: 0.8000\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4350 - acc: 0.8000\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3302 - acc: 0.9000\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3862 - acc: 0.8000\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3998 - acc: 0.8000\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3408 - acc: 0.9000\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.3440 - acc: 0.9000\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3036 - acc: 0.9000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.2920 - acc: 0.9000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.2853 - acc: 0.9000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.2792 - acc: 0.9000\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.2585 - acc: 0.9000\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.2456 - acc: 0.9000\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.2376 - acc: 0.9000\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.2251 - acc: 0.9000\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.2077 - acc: 0.9000\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.2040 - acc: 0.9000\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1867 - acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1704 - acc: 0.9000\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1477 - acc: 0.9000\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1329 - acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1331 - acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1057 - acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0728 - acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0640 - acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0525 - acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4222 - acc: 0.9000\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.7919 - acc: 0.6000\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3260 - acc: 0.8000\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.5120 - acc: 0.8000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.2001 - acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.1518 - acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.1810 - acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3559 - acc: 0.8000\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3041 - acc: 0.9000\n",
      "Epoch 75/100\n",
      " - 0s - loss: 1.6658 - acc: 0.6000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 1.1969 - acc: 0.8000\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.9537 - acc: 0.6000\n",
      "Epoch 78/100\n",
      " - 0s - loss: 2.0718 - acc: 0.7000\n",
      "Epoch 79/100\n",
      " - 0s - loss: 2.8098 - acc: 0.7000\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.9377 - acc: 0.6000\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.5413 - acc: 0.8000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.6322 - acc: 0.7000\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.6208 - acc: 0.7000\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.6205 - acc: 0.7000\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.6201 - acc: 0.7000\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.6198 - acc: 0.7000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.6194 - acc: 0.7000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.6191 - acc: 0.7000\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.6188 - acc: 0.7000\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.6184 - acc: 0.7000\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.6181 - acc: 0.7000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.6178 - acc: 0.7000\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.6175 - acc: 0.7000\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.6172 - acc: 0.7000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.6169 - acc: 0.7000\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6166 - acc: 0.7000\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.6163 - acc: 0.7000\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6161 - acc: 0.7000\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6158 - acc: 0.7000\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6156 - acc: 0.7000\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(x_train[:10], y_train[:10], epochs=100, batch_size=10, validation_split=0, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_arquitecture()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146 samples, validate on 37 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 3.9808 - acc: 0.5068 - val_loss: 11.7619 - val_acc: 0.2703\n",
      "Epoch 2/100\n",
      " - 0s - loss: 10.3074 - acc: 0.3425 - val_loss: 11.7619 - val_acc: 0.2703\n",
      "Epoch 3/100\n",
      " - 0s - loss: 10.2366 - acc: 0.3562 - val_loss: 11.7619 - val_acc: 0.2703\n",
      "Epoch 4/100\n",
      " - 0s - loss: 9.8558 - acc: 0.3562 - val_loss: 11.7619 - val_acc: 0.2703\n",
      "Epoch 5/100\n",
      " - 0s - loss: 9.8045 - acc: 0.3630 - val_loss: 11.7619 - val_acc: 0.2703\n",
      "Epoch 6/100\n",
      " - 0s - loss: 9.5420 - acc: 0.3630 - val_loss: 11.3391 - val_acc: 0.2973\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.9677 - acc: 0.5411 - val_loss: 0.7441 - val_acc: 0.7297\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6546 - acc: 0.6438 - val_loss: 0.6077 - val_acc: 0.7297\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.6369 - acc: 0.6712 - val_loss: 1.0372 - val_acc: 0.7297\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.7111 - acc: 0.6575 - val_loss: 0.6329 - val_acc: 0.7297\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.6521 - acc: 0.6575 - val_loss: 0.7089 - val_acc: 0.7297\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.6391 - acc: 0.6575 - val_loss: 0.6196 - val_acc: 0.7297\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.6605 - acc: 0.6575 - val_loss: 0.9415 - val_acc: 0.7297\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.6662 - acc: 0.6575 - val_loss: 0.5792 - val_acc: 0.7297\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.6933 - acc: 0.6575 - val_loss: 0.6650 - val_acc: 0.7297\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.6736 - acc: 0.6575 - val_loss: 0.6594 - val_acc: 0.7297\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.6694 - acc: 0.6575 - val_loss: 0.6523 - val_acc: 0.7297\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.6645 - acc: 0.6575 - val_loss: 0.6444 - val_acc: 0.7297\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.6600 - acc: 0.6575 - val_loss: 0.6369 - val_acc: 0.7297\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.6563 - acc: 0.6575 - val_loss: 0.6299 - val_acc: 0.7297\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.6527 - acc: 0.6575 - val_loss: 0.6241 - val_acc: 0.7297\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.6513 - acc: 0.6575 - val_loss: 0.6186 - val_acc: 0.7297\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.6481 - acc: 0.6575 - val_loss: 0.6149 - val_acc: 0.7297\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.6466 - acc: 0.6575 - val_loss: 0.6118 - val_acc: 0.7297\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.6458 - acc: 0.6575 - val_loss: 0.6089 - val_acc: 0.7297\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.6453 - acc: 0.6575 - val_loss: 0.6065 - val_acc: 0.7297\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.6445 - acc: 0.6575 - val_loss: 0.6049 - val_acc: 0.7297\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.6438 - acc: 0.6575 - val_loss: 0.6038 - val_acc: 0.7297\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.6437 - acc: 0.6575 - val_loss: 0.6023 - val_acc: 0.7297\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.6433 - acc: 0.6575 - val_loss: 0.6012 - val_acc: 0.7297\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.6433 - acc: 0.6575 - val_loss: 0.5999 - val_acc: 0.7297\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5991 - val_acc: 0.7297\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5982 - val_acc: 0.7297\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.6430 - acc: 0.6575 - val_loss: 0.5975 - val_acc: 0.7297\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5973 - val_acc: 0.7297\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5974 - val_acc: 0.7297\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5975 - val_acc: 0.7297\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5974 - val_acc: 0.7297\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5976 - val_acc: 0.7297\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5978 - val_acc: 0.7297\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5979 - val_acc: 0.7297\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5977 - val_acc: 0.7297\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5977 - val_acc: 0.7297\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5975 - val_acc: 0.7297\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5973 - val_acc: 0.7297\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5971 - val_acc: 0.7297\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5968 - val_acc: 0.7297\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5963 - val_acc: 0.7297\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5959 - val_acc: 0.7297\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5958 - val_acc: 0.7297\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5956 - val_acc: 0.7297\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5957 - val_acc: 0.7297\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5954 - val_acc: 0.7297\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5951 - val_acc: 0.7297\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5953 - val_acc: 0.7297\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5951 - val_acc: 0.7297\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5950 - val_acc: 0.7297\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5947 - val_acc: 0.7297\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5949 - val_acc: 0.7297\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5950 - val_acc: 0.7297\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5951 - val_acc: 0.7297\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5951 - val_acc: 0.7297\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5946 - val_acc: 0.7297\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5945 - val_acc: 0.7297\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5943 - val_acc: 0.7297\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5943 - val_acc: 0.7297\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5942 - val_acc: 0.7297\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5943 - val_acc: 0.7297\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5945 - val_acc: 0.7297\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5944 - val_acc: 0.7297\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5946 - val_acc: 0.7297\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5949 - val_acc: 0.7297\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5949 - val_acc: 0.7297\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5950 - val_acc: 0.7297\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5947 - val_acc: 0.7297\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5944 - val_acc: 0.7297\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5944 - val_acc: 0.7297\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5945 - val_acc: 0.7297\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5948 - val_acc: 0.7297\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5951 - val_acc: 0.7297\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5955 - val_acc: 0.7297\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5953 - val_acc: 0.7297\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5951 - val_acc: 0.7297\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5949 - val_acc: 0.7297\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5949 - val_acc: 0.7297\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.6429 - acc: 0.6575 - val_loss: 0.5953 - val_acc: 0.7297\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5950 - val_acc: 0.7297\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5949 - val_acc: 0.7297\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5951 - val_acc: 0.7297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5952 - val_acc: 0.7297\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5953 - val_acc: 0.7297\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6428 - acc: 0.6575 - val_loss: 0.5955 - val_acc: 0.7297\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6427 - acc: 0.6575 - val_loss: 0.5953 - val_acc: 0.7297\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
